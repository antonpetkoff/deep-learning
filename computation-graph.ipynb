{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation:\n",
    "    \"\"\"Represents a Node in the Computation Graph\"\"\"\n",
    "    \n",
    "    def __init__(self, input_nodes = []):\n",
    "        \"\"\"Constructs an Operation with input_nodes as inputs\n",
    "           which computes outputs to zero or more consumers\"\"\"\n",
    "        self.input_nodes = input_nodes\n",
    "        self.consumers = []\n",
    "        \n",
    "        # Connect this node with its inputs, by adding it as a consumer to its inputs\n",
    "        for input_node in self.input_nodes:\n",
    "            input_node.consumers.append(self)\n",
    "        \n",
    "        # Add this operation to the Computation Graph\n",
    "        # TODO: provide the graph explicitly\n",
    "        _default_graph.operations.append(self)\n",
    "    \n",
    "    def compute(self):\n",
    "        \"\"\"Computes the output of the operation. Depends on the specific operation.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Operation):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__(input_nodes=[x, y])\n",
    "    \n",
    "    def compute(self, x, y):\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matmul(Operation):\n",
    "    def __init__(self, A, B):\n",
    "        super().__init__(input_nodes=[A, B])\n",
    "\n",
    "    def compute(self, A, B):\n",
    "        return A.dot(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Operation):\n",
    "    def __init__(self, x):\n",
    "        super().__init__(input_nodes=[x])\n",
    "    \n",
    "    def compute(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Operation):\n",
    "    def __init__(self, x):\n",
    "        super().__init__(input_nodes=[x])\n",
    "    \n",
    "    def compute(self, x):\n",
    "        \"\"\"The input of Softmax is a vector\"\"\"\n",
    "        # using vector operations\n",
    "        # axis=1 so that for each row we sum its colums\n",
    "        # broadcast the sum\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Placeholder:\n",
    "    \"\"\"Represents an input node which doesn't have any inputs\n",
    "       and can only be consumed by other Nodes in the Computation Graph.\n",
    "       \n",
    "       The Placeholder has a fixed value. Acts like a constant.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.consumers = []\n",
    "        \n",
    "        # Register the placeholder in the Computation Graph\n",
    "        # TODO: provide the graph explicitly\n",
    "        _default_graph.placeholders.append(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    \"\"\"Represents a parameter in the Computation Graph.\n",
    "       This node doesn't have any inputs and has only consumers.\n",
    "       \n",
    "       The Variable's value can change. It is initialized to initial_value.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_value=None):\n",
    "        self.value = initial_value\n",
    "        self.consumers = []\n",
    "        \n",
    "        # Register the variable in the Computation Graph\n",
    "        # TODO: provide the graph explicitly\n",
    "        _default_graph.variables.append(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \"\"\"Represents the actual Computation Graph which has 3 types of Nodes:\n",
    "       - placeholders\n",
    "       - variables\n",
    "       - operations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, placeholders=[], variables=[], operations=[]):\n",
    "        self.placeholders = placeholders\n",
    "        self.variables = variables\n",
    "        self.operations = operations\n",
    "\n",
    "    def as_default(self):\n",
    "        global _default_graph\n",
    "        _default_graph = self\n",
    "        return _default_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Session:\n",
    "    \"\"\"Represents a single execution of the whole Computation graph.\"\"\"\n",
    "    # TODO: provide the Graph explicitly\n",
    "    \n",
    "    def run(self, operation, feed_dict={}):\n",
    "        \"\"\"Performs a post-order traversal of all nodes in the Computation graph,\n",
    "           so that all operations with known inputs are performed first.\n",
    "        \"\"\"\n",
    "        \n",
    "        nodes_in_post_order = Session.traverse_post_order(operation)\n",
    "        \n",
    "        outputs = {operation: None for operation in nodes_in_post_order}\n",
    "        \n",
    "        for node in nodes_in_post_order:\n",
    "            if type(node) == Placeholder:\n",
    "                outputs[node] = feed_dict[node]\n",
    "            elif type(node) == Variable:\n",
    "                outputs[node] = node.value\n",
    "            elif isinstance(node, Operation):\n",
    "                computed_inputs = [outputs[input_node] for input_node in node.input_nodes]\n",
    "                outputs[node] = node.compute(*computed_inputs)\n",
    "\n",
    "        return outputs[operation]\n",
    "\n",
    "    @staticmethod\n",
    "    def traverse_post_order(operation):\n",
    "        operations_post_order = []\n",
    "        \n",
    "        def traverse(node):\n",
    "            # Placeholders and Variables do not have input_nodes\n",
    "            if isinstance(node, Operation):\n",
    "                for input_node in node.input_nodes:\n",
    "                    traverse(input_node)\n",
    "\n",
    "            operations_post_order.append(node)\n",
    "        \n",
    "        traverse(operation)\n",
    "        return operations_post_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, -1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Perceptron\n",
    "\n",
    "graph = Graph().as_default()\n",
    "\n",
    "A = Variable(np.array([\n",
    "    [1, 0],\n",
    "    [0, -1]\n",
    "]))\n",
    "b = Variable(np.array([1, 1]))\n",
    "\n",
    "x = Placeholder()\n",
    "\n",
    "y = Add(Matmul(A, x), b)\n",
    "\n",
    "Session().run(y, feed_dict={\n",
    "    x: np.array([1, 2])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5430130213827837"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sigmoid Perceptron\n",
    "\n",
    "graph = Graph().as_default()\n",
    "\n",
    "x = Placeholder()\n",
    "w = Variable(initial_value=np.random.normal(0, 1, 2))\n",
    "b = Variable(initial_value=np.random.normal(0, 1))\n",
    "\n",
    "perceptron = Sigmoid(Add(Matmul(w, x), b))\n",
    "\n",
    "Session().run(perceptron, feed_dict={\n",
    "    x: np.array([-1, 1])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 403.43127224 1096.63407031 8103.08405099 8103.08405099]\n",
      "[[ 403.43127224]\n",
      " [1096.63407031]\n",
      " [8103.08405099]\n",
      " [8103.08405099]]\n",
      "[[2.47875218e-03 4.03428793e+02]\n",
      " [9.11881966e-04 1.09663316e+03]\n",
      " [8.10308393e+03 1.23409804e-04]\n",
      " [8.10308393e+03 1.23409804e-04]]\n",
      "[[6.14417460e-06 9.99993856e-01]\n",
      " [8.31528028e-07 9.99999168e-01]\n",
      " [9.99999985e-01 1.52299795e-08]\n",
      " [9.99999985e-01 1.52299795e-08]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,2) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-401f45a832e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     ])\n\u001b[1;32m     24\u001b[0m })\n",
      "\u001b[0;32m<ipython-input-10-2b7ee5922e9f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, operation, feed_dict)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mcomputed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_node\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcomputed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4a7fcb64ec8a>\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,2) (4,) "
     ]
    }
   ],
   "source": [
    "# Multi-class Perceptron\n",
    "\n",
    "graph = Graph().as_default()\n",
    "\n",
    "# will be a matrix used for batch computation\n",
    "X = Placeholder()\n",
    "\n",
    "W = Variable(np.array([\n",
    "    [1, -1],\n",
    "    [1, -1]\n",
    "]))\n",
    "\n",
    "b = Variable(np.array([0, 0]))\n",
    "\n",
    "classifier = Softmax(Add(Matmul(X, W), b))\n",
    "\n",
    "Session().run(classifier, {\n",
    "    X: np.array([\n",
    "        [-3, -3],\n",
    "        [-3, -4],\n",
    "        [4, 5],\n",
    "        [3, 6]\n",
    "    ])\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
